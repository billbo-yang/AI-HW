{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit ('env')",
   "display_name": "Python 3.7.3 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "8bce53a5dddf8b1e7c4b1e0a971c1035f57fa3c7c5f676ba2a4fbddf261c29d8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dependencies imported\n"
     ]
    }
   ],
   "source": [
    "#   import necessary dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"dependencies imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data mean should be near 0: 1.258252761241844e-17\nData standard deviation should be 1: 1.0\n-----\n"
     ]
    }
   ],
   "source": [
    "#   load the data\n",
    "filename = '../chronic_kidney_disease_full.arff'\n",
    "data = arff.load(open('../chronic_kidney_disease_full.arff'))\n",
    "df = pd.DataFrame(data['data'])\n",
    "\n",
    "#last column of df is our target column in terms of ckd, notckd\n",
    "target = df.iloc[:, -1:]\n",
    "df.drop(df.columns[[24]], axis=1, inplace=True)\n",
    "\n",
    "target = target.rename({24: 1}, axis=1)\n",
    "target = target.replace(\"ckd\", 1)\n",
    "target = target.replace(\"notckd\", 0)\n",
    "target = target.T\n",
    "target = target.to_numpy()[0]\n",
    "# print(target)\n",
    "\n",
    "# format data oh god\n",
    "df = df.replace(\"yes\", 1)\n",
    "df = df.replace(\"no\", 0)\n",
    "df = df.replace(\"present\", 1)\n",
    "df = df.replace(\"notpresent\", 0)\n",
    "df = df.replace(\"normal\", 1)\n",
    "df = df.replace(\"abnormal\", 0)\n",
    "df = df.replace(\"good\", 1)\n",
    "df = df.replace(\"poor\", 0)\n",
    "df = df.replace(\"1.005\", 1.005)\n",
    "df = df.replace(\"1.010\", 1.01)\n",
    "df = df.replace(\"1.015\", 1.015)\n",
    "df = df.replace(\"1.020\", 1.020)\n",
    "df = df.replace(\"1.025\", 1.025)\n",
    "df = df.replace(\"0\", 0)\n",
    "df = df.replace(\"1\", 1)\n",
    "df = df.replace(\"2\", 2)\n",
    "df = df.replace(\"3\", 3)\n",
    "df = df.replace(\"4\", 4)\n",
    "df = df.replace(\"5\", 5)\n",
    "df = df.replace(\"None\", -1)\n",
    "df = df.fillna(-1)\n",
    "\n",
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "df = scaler.fit_transform(df)\n",
    "print(\"Data mean should be near 0:\", df.mean())\n",
    "print(\"Data standard deviation should be 1:\", df.std())\n",
    "print(\"-----\")\n",
    "dataDf = pd.DataFrame(df)\n",
    "targetDf = pd.DataFrame(target)\n",
    "data = np.array(df)\n",
    "target = np.array(target)\n",
    "\n",
    "# print(data.shape)\n",
    "# print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   function to calculate f-measure\n",
    "def f_measure(pred, y_test):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(pred)):\n",
    "        currPred = pred[i]\n",
    "        currTest = y_test[i]\n",
    "\n",
    "        if currPred == 1 and currTest == 1:\n",
    "            TP+=1\n",
    "        elif currPred == 0 and currTest == 0:\n",
    "            TN+=1\n",
    "        elif currPred == 1 and currTest == 0:\n",
    "            FP+=1\n",
    "        elif currPred == 0 and currTest == 1:\n",
    "            FN+=1\n",
    "    \n",
    "    pre = TP/(TP+FP)\n",
    "    rec = TP/(TP+FN)\n",
    "    return (2 * pre * rec)/(pre + rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train : (320, 24)\ny_train : (320,)\nX_test : (80, 24)\ny_test : (80,)\nF-Measure: 0.9885057471264368\n"
     ]
    }
   ],
   "source": [
    "#   (a) Support Vector Machine w/ linear kernal and default parameters\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=.2, random_state=5)\n",
    "print(\"X_train : \" + str(X_train.shape))\n",
    "print(\"y_train : \" + str(y_train.shape))\n",
    "print(\"X_test : \" + str(X_test.shape))\n",
    "print(\"y_test : \" + str(y_test.shape))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "# print(pred)\n",
    "# print(y_test)\n",
    "\n",
    "# calculate f-measure\n",
    "print(\"F-Measure: {}\".format(f_measure(pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train : (320, 24)\ny_train : (320,)\nX_test : (80, 24)\ny_test : (80,)\nF-Measure: 0.9885057471264368\n"
     ]
    }
   ],
   "source": [
    "#   (b) Support Vector Machine w/ rbf kernal and default parameters\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=.2, random_state=5)\n",
    "print(\"X_train : \" + str(X_train.shape))\n",
    "print(\"y_train : \" + str(y_train.shape))\n",
    "print(\"X_test : \" + str(X_test.shape))\n",
    "print(\"y_test : \" + str(y_test.shape))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "# print(pred)\n",
    "# print(y_test)\n",
    "\n",
    "# calculate f-measure\n",
    "print(\"F-Measure: {}\".format(f_measure(pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train : (320, 24)\ny_train : (320,)\nX_test : (80, 24)\ny_test : (80,)\nF-Measure: 1.0\n"
     ]
    }
   ],
   "source": [
    "#   (c) Random forest with default parameters\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=.2, random_state=5)\n",
    "print(\"X_train : \" + str(X_train.shape))\n",
    "print(\"y_train : \" + str(y_train.shape))\n",
    "print(\"X_test : \" + str(X_test.shape))\n",
    "print(\"y_test : \" + str(y_test.shape))\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "# print(pred)\n",
    "# print(y_test)\n",
    "\n",
    "#calculate f-measure\n",
    "print(\"F-Measure: {}\".format(f_measure(pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}